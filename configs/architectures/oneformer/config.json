{
    "_commit_hash": null,
    "architectures": [
      "ModifiedOneFormerForUniversalSegmentation"
    ],
    "backbone_config": null,
    "class_weight": 2.0,
    "common_stride": 4,
    "contrastive_temperature": 0.07,
    "contrastive_weight": 0.5,
    "conv_dim": 256,
    "decoder_layers": 10,
    "dice_weight": 5.0,
    "dim_feedforward": 2048,
    "dropout": 0.1,
    "encoder_feedforward_dim": 1024,
    "encoder_layers": 6,
    "enforce_input_proj": false,
    "hidden_dim": 256,
    "id2label": null,
    "ignore_value": 255,
    "importance_sample_ratio": 0.75,
    "init_std": 0.02,
    "init_xavier_std": 1.0,
    "is_training": false,
    "label2id": null,
    "layer_norm_eps": 1e-05,
    "mask_dim": 256,
    "mask_weight": 5.0,
    "max_seq_len": 77,
    "model_type": "oneformer",
    "no_object_weight": 0.1,
    "norm": "GN",
    "num_attention_heads": 8,
    "num_classes": 150,
    "num_hidden_layers": 10,
    "num_queries": 150,
    "output_attentions": true,
    "output_auxiliary_logits": true,
    "output_hidden_states": true,
    "oversample_ratio": 3.0,
    "pre_norm": false,
    "query_dec_layers": 2,
    "strides": [
      4,
      8,
      16,
      32
    ],
    "task_seq_len": 77,
    "text_encoder_context_length": 77,
    "text_encoder_n_ctx": 16,
    "text_encoder_num_layers": 6,
    "text_encoder_proj_layers": 2,
    "text_encoder_vocab_size": 49408,
    "text_encoder_width": 256,
    "torch_dtype": "float32",
    "train_num_points": 12544,
    "transformers_version": null,
    "use_auxiliary_loss": true,
    "use_task_norm": true
  }
  