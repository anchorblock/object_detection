{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change the current directory to root directory\n",
    "new_directory = \"../\"\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Verify the current directory has changed\n",
    "updated_directory = os.getcwd()\n",
    "print(\"Updated Directory:\", updated_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "\n",
    "from transformers import MaskFormerImageProcessor\n",
    "\n",
    "from transformers import MaskFormerForInstanceSegmentation, MaskFormerConfig, MaskFormerModel, DetrConfig, DetrForObjectDetection, FocalNetConfig, FocalNetModel, FocalNetForImageClassification, MaskFormerConfig, AutoBackbone, Mask2FormerConfig, AutoConfig, AutoModel\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "from models import AutoModelForPanopticSegmentation, CustomMask2FormerConfig, AutoPanopticConfig\n",
    "\n",
    "\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/convnext-large-224\"\n",
    "\n",
    "backbone_config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "# generate model config **dict\n",
    "\n",
    "backbone = AutoModel.from_pretrained(model_name)\n",
    "model_configuration = AutoPanopticConfig(model_type = \"custom_mask2former\", backbone_config=backbone.config)\n",
    "\n",
    "print(model_configuration)\n",
    "\n",
    "\n",
    "model = AutoModelForPanopticSegmentation.from_config(model_configuration, backbone = backbone)\n",
    "\n",
    "\n",
    "# load MaskFormer fine-tuned on COCO panoptic segmentation\n",
    "feature_extractor = MaskFormerImageProcessor.from_pretrained(\"facebook/mask2former-swin-tiny-coco-panoptic\")\n",
    "\n",
    "\n",
    "# model = AutoModelForPanopticSegmentation.from_pretrained(\"facebook/maskformer-swin-tiny-coco\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# model predicts class_queries_logits of shape `(batch_size, num_queries)`\n",
    "# and masks_queries_logits of shape `(batch_size, num_queries, height, width)`\n",
    "class_queries_logits = outputs.class_queries_logits\n",
    "masks_queries_logits = outputs.masks_queries_logits\n",
    "\n",
    "# you can pass them to feature_extractor for postprocessing\n",
    "result = feature_extractor.post_process_panoptic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "# we refer to the demo notebooks for visualization (see \"Resources\" section in the MaskFormer docs)\n",
    "\n",
    "\n",
    "predicted_panoptic_map = result[\"segmentation\"]\n",
    "\n",
    "# Get segments_info\n",
    "segments_info = result['segments_info']\n",
    "\n",
    "\n",
    "# Convert the tensor to numpy\n",
    "image_array = predicted_panoptic_map.numpy()\n",
    "\n",
    "# Normalize the array to the range 0-255\n",
    "min_value = np.min(image_array)\n",
    "max_value = np.max(image_array)\n",
    "\n",
    "if min_value == max_value:\n",
    "    normalized_array = np.zeros_like(image_array)\n",
    "else:\n",
    "    normalized_array = (image_array - min_value) * (255 / (max_value - min_value))\n",
    "\n",
    "\n",
    "# Convert the array to uint8 data type\n",
    "uint8_array = normalized_array.astype(np.uint8)\n",
    "\n",
    "# Create a PIL image from the uint8 array\n",
    "image = Image.fromarray(uint8_array)\n",
    "\n",
    "# Load the labels dictionary from the model configuration (model.config.id2label)\n",
    "id2label = model.config.id2label\n",
    "\n",
    "\n",
    "# Create a PIL draw object\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Iterate over the segments_info dictionary\n",
    "for segment in segments_info:\n",
    "    segment_id = segment['id']\n",
    "    label_id = segment['label_id']\n",
    "    label = id2label[label_id]\n",
    "    score = segment['score']\n",
    "    \n",
    "    # Get the bounding box coordinates for the segment\n",
    "    bbox = np.argwhere(image_array == segment_id)\n",
    "    ymin, xmin = np.min(bbox, axis=0)\n",
    "    ymax, xmax = np.max(bbox, axis=0)\n",
    "    \n",
    "    # Draw the bounding box rectangle\n",
    "    draw.rectangle([(xmin, ymin), (xmax, ymax)], outline='white')\n",
    "    \n",
    "    # Add label text\n",
    "    text = f\"{label} ({score:.2f})\"\n",
    "    draw.text((xmin, ymin - 12), text, fill='white')\n",
    "\n",
    "\n",
    "# Save the image\n",
    "image.save('predicted_panoptic_map.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
