{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change the current directory to root directory\n",
    "new_directory = \"../../\"\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Verify the current directory has changed\n",
    "updated_directory = os.getcwd()\n",
    "print(\"Updated Directory:\", updated_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferenece 1: Bounding Box Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "\n",
    "from transformers import AutoImageProcessor\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "from models import AutoModelForPanopticSegmentation\n",
    "\n",
    "\n",
    "# load MaskFormer fine-tuned on COCO panoptic segmentation\n",
    "feature_extractor = AutoImageProcessor.from_pretrained(\"facebook/maskformer-swin-tiny-coco\")\n",
    "model = AutoModelForPanopticSegmentation.from_pretrained(\"facebook/maskformer-swin-tiny-coco\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# you can pass them to feature_extractor for postprocessing\n",
    "result = feature_extractor.post_process_panoptic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "\n",
    "predicted_panoptic_map = result[\"segmentation\"]\n",
    "segments_info = result['segments_info']\n",
    "\n",
    "# Convert the tensor to numpy\n",
    "image_array = predicted_panoptic_map.numpy()\n",
    "\n",
    "# Normalize the array to the range 0-255\n",
    "normalized_array = (image_array - np.min(image_array)) * (255 / (np.max(image_array) - np.min(image_array)))\n",
    "\n",
    "# Convert the array to uint8 data type\n",
    "uint8_array = normalized_array.astype(np.uint8)\n",
    "\n",
    "# Create a PIL image from the uint8 array\n",
    "image_gen_mask = Image.fromarray(uint8_array)\n",
    "\n",
    "# Load the labels dictionary from the model configuration (model.config.id2label)\n",
    "id2label = model.config.id2label\n",
    "\n",
    "\n",
    "# Create a PIL draw object\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Iterate over the segments_info dictionary\n",
    "for segment in segments_info:\n",
    "    segment_id = segment['id']\n",
    "    label_id = segment['label_id']\n",
    "    label = id2label[label_id]\n",
    "    if int(label_id) > 79:\n",
    "        continue\n",
    "    score = segment['score']\n",
    "    \n",
    "    # Get the bounding box coordinates for the segment\n",
    "    bbox = np.argwhere(image_array == segment_id)\n",
    "    ymin, xmin = np.min(bbox, axis=0)\n",
    "    ymax, xmax = np.max(bbox, axis=0)\n",
    "    \n",
    "    # Draw the bounding box rectangle\n",
    "    draw.rectangle([(xmin, ymin), (xmax, ymax)], outline='white')\n",
    "    \n",
    "    # Add label text\n",
    "    text = f\"{label} ({score:.2f})\"\n",
    "    draw.text((xmin, ymin - 12), text, fill='white')\n",
    "\n",
    "\n",
    "# Save the image\n",
    "image.save('predicted_detection_map.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
