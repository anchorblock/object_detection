MaskFormerForInstanceSegmentation(
  (model): MaskFormerModel(
    (pixel_level_module): MaskFormerPixelLevelModule(
      (encoder): MaskFormerSwinBackbone(
        (model): MaskFormerSwinModel(
          (embeddings): MaskFormerSwinEmbeddings(
            (patch_embeddings): MaskFormerSwinPatchEmbeddings(
              (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))
            )
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (encoder): MaskFormerSwinEncoder(
            (layers): ModuleList(
              (0): MaskFormerSwinStage(
                (blocks): ModuleList(
                  (0-1): 2 x MaskFormerSwinLayer(
                    (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                    (attention): MaskFormerSwinAttention(
                      (self): MaskFormerSwinSelfAttention(
                        (query): Linear(in_features=128, out_features=128, bias=True)
                        (key): Linear(in_features=128, out_features=128, bias=True)
                        (value): Linear(in_features=128, out_features=128, bias=True)
                        (dropout): Dropout(p=0.0, inplace=False)
                      )
                      (output): MaskFormerSwinSelfOutput(
                        (dense): Linear(in_features=128, out_features=128, bias=True)
                        (dropout): Dropout(p=0.0, inplace=False)
                      )
                    )
                    (drop_path): MaskFormerSwinDropPath(p=0.3)
                    (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                    (intermediate): MaskFormerSwinIntermediate(
                      (dense): Linear(in_features=128, out_features=512, bias=True)
                      (intermediate_act_fn): GELUActivation()
                    )
                    (output): MaskFormerSwinOutput(
                      (dense): Linear(in_features=512, out_features=128, bias=True)
                      (dropout): Dropout(p=0.0, inplace=False)
                    )
                  )
                )
                (downsample): MaskFormerSwinPatchMerging(
                  (reduction): Linear(in_features=512, out_features=256, bias=False)
                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                )
              )
              (1): MaskFormerSwinStage(
                (blocks): ModuleList(
                  (0-1): 2 x MaskFormerSwinLayer(
                    (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (attention): MaskFormerSwinAttention(
                      (self): MaskFormerSwinSelfAttention(
                        (query): Linear(in_features=256, out_features=256, bias=True)
                        (key): Linear(in_features=256, out_features=256, bias=True)
                        (value): Linear(in_features=256, out_features=256, bias=True)
                        (dropout): Dropout(p=0.0, inplace=False)
                      )
                      (output): MaskFormerSwinSelfOutput(
                        (dense): Linear(in_features=256, out_features=256, bias=True)
                        (dropout): Dropout(p=0.0, inplace=False)
                      )
                    )
                    (drop_path): MaskFormerSwinDropPath(p=0.3)
                    (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                    (intermediate): MaskFormerSwinIntermediate(
                      (dense): Linear(in_features=256, out_features=1024, bias=True)
                      (intermediate_act_fn): GELUActivation()
                    )
                    (output): MaskFormerSwinOutput(
                      (dense): Linear(in_features=1024, out_features=256, bias=True)
                      (dropout): Dropout(p=0.0, inplace=False)
                    )
                  )
                )
                (downsample): MaskFormerSwinPatchMerging(
                  (reduction): Linear(in_features=1024, out_features=512, bias=False)
                  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                )
              )
              (2): MaskFormerSwinStage(
                (blocks): ModuleList(
                  (0-17): 18 x MaskFormerSwinLayer(
                    (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                    (attention): MaskFormerSwinAttention(
                      (self): MaskFormerSwinSelfAttention(
                        (query): Linear(in_features=512, out_features=512, bias=True)
                        (key): Linear(in_features=512, out_features=512, bias=True)
                        (value): Linear(in_features=512, out_features=512, bias=True)
                        (dropout): Dropout(p=0.0, inplace=False)
                      )
                      (output): MaskFormerSwinSelfOutput(
                        (dense): Linear(in_features=512, out_features=512, bias=True)
                        (dropout): Dropout(p=0.0, inplace=False)
                      )
                    )
                    (drop_path): MaskFormerSwinDropPath(p=0.3)
                    (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                    (intermediate): MaskFormerSwinIntermediate(
                      (dense): Linear(in_features=512, out_features=2048, bias=True)
                      (intermediate_act_fn): GELUActivation()
                    )
                    (output): MaskFormerSwinOutput(
                      (dense): Linear(in_features=2048, out_features=512, bias=True)
                      (dropout): Dropout(p=0.0, inplace=False)
                    )
                  )
                )
                (downsample): MaskFormerSwinPatchMerging(
                  (reduction): Linear(in_features=2048, out_features=1024, bias=False)
                  (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
                )
              )
              (3): MaskFormerSwinStage(
                (blocks): ModuleList(
                  (0-1): 2 x MaskFormerSwinLayer(
                    (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                    (attention): MaskFormerSwinAttention(
                      (self): MaskFormerSwinSelfAttention(
                        (query): Linear(in_features=1024, out_features=1024, bias=True)
                        (key): Linear(in_features=1024, out_features=1024, bias=True)
                        (value): Linear(in_features=1024, out_features=1024, bias=True)
                        (dropout): Dropout(p=0.0, inplace=False)
                      )
                      (output): MaskFormerSwinSelfOutput(
                        (dense): Linear(in_features=1024, out_features=1024, bias=True)
                        (dropout): Dropout(p=0.0, inplace=False)
                      )
                    )
                    (drop_path): MaskFormerSwinDropPath(p=0.3)
                    (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                    (intermediate): MaskFormerSwinIntermediate(
                      (dense): Linear(in_features=1024, out_features=4096, bias=True)
                      (intermediate_act_fn): GELUActivation()
                    )
                    (output): MaskFormerSwinOutput(
                      (dense): Linear(in_features=4096, out_features=1024, bias=True)
                      (dropout): Dropout(p=0.0, inplace=False)
                    )
                  )
                )
              )
            )
          )
          (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (pooler): AdaptiveAvgPool1d(output_size=1)
        )
        (hidden_states_norms): ModuleList(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder): MaskFormerPixelDecoder(
        (fpn): MaskFormerFPNModel(
          (stem): MaskFormerFPNConvLayer(
            (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): GroupNorm(32, 256, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (layers): Sequential(
            (0): MaskFormerFPNLayer(
              (proj): Sequential(
                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              )
              (block): MaskFormerFPNConvLayer(
                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
                (2): ReLU(inplace=True)
              )
            )
            (1): MaskFormerFPNLayer(
              (proj): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              )
              (block): MaskFormerFPNConvLayer(
                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
                (2): ReLU(inplace=True)
              )
            )
            (2): MaskFormerFPNLayer(
              (proj): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              )
              (block): MaskFormerFPNConvLayer(
                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
        (mask_projection): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (transformer_module): MaskFormerTransformerModule(
      (position_embedder): MaskFormerSinePositionEmbedding()
      (queries_embedder): Embedding(100, 256)
      (input_projection): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      (decoder): DetrDecoder(
        (layers): ModuleList(
          (0-5): 6 x DetrDecoderLayer(
            (self_attn): DetrAttention(
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (activation_fn): ReLU()
            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): DetrAttention(
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=256, out_features=2048, bias=True)
            (fc2): Linear(in_features=2048, out_features=256, bias=True)
            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (class_predictor): Linear(in_features=256, out_features=151, bias=True)
  (mask_embedder): MaskformerMLPPredictionHead(
    (0): PredictionBlock(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ReLU()
    )
    (1): PredictionBlock(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ReLU()
    )
    (2): PredictionBlock(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): Identity()
    )
  )
  (matcher): Matcher MaskFormerHungarianMatcher
      cost_class: 1.0
      cost_mask: 20.0
      cost_dice: 1.0
  (criterion): MaskFormerLoss(
    (matcher): Matcher MaskFormerHungarianMatcher
        cost_class: 1.0
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
********************************
MaskFormerForInstanceSegmentation(
  (model): MaskFormerModel(
    (pixel_level_module): MaskFormerPixelLevelModule(
      (encoder): MaskFormerSwinBackbone(
        (model): FocalNetModel(
          (embeddings): FocalNetEmbeddings(
            (patch_embeddings): FocalNetPatchEmbeddings(
              (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
            )
            (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (encoder): FocalNetEncoder(
            (stages): ModuleList(
              (0): FocalNetStage(
                (layers): ModuleList(
                  (0): FocalNetLayer(
                    (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=96, out_features=195, bias=True)
                      (projection_context): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=96, out_features=96, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): Identity()
                    (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=96, out_features=384, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=384, out_features=96, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (1): FocalNetLayer(
                    (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=96, out_features=195, bias=True)
                      (projection_context): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=96, out_features=96, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): FocalNetDropPath(p=0.00909090880304575)
                    (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=96, out_features=384, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=384, out_features=96, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                )
                (downsample): FocalNetPatchEmbeddings(
                  (projection): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
                  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                )
              )
              (1): FocalNetStage(
                (layers): ModuleList(
                  (0): FocalNetLayer(
                    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=192, out_features=387, bias=True)
                      (projection_context): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=192, out_features=192, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): FocalNetDropPath(p=0.0181818176060915)
                    (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=192, out_features=768, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=768, out_features=192, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (1): FocalNetLayer(
                    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=192, out_features=387, bias=True)
                      (projection_context): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=192, out_features=192, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): FocalNetDropPath(p=0.027272727340459824)
                    (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=192, out_features=768, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=768, out_features=192, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                )
                (downsample): FocalNetPatchEmbeddings(
                  (projection): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
                  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                )
              )
              (2): FocalNetStage(
                (layers): ModuleList(
                  (0): FocalNetLayer(
                    (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=384, out_features=771, bias=True)
                      (projection_context): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=384, out_features=384, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): FocalNetDropPath(p=0.036363635212183)
                    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=384, out_features=1536, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=1536, out_features=384, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (1): FocalNetLayer(
                    (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=384, out_features=771, bias=True)
                      (projection_context): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=384, out_features=384, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): FocalNetDropPath(p=0.045454543083906174)
                    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=384, out_features=1536, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=1536, out_features=384, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (2): FocalNetLayer(
                    (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=384, out_features=771, bias=True)
                      (projection_context): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=384, out_features=384, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): FocalNetDropPath(p=0.054545458406209946)
                    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=384, out_features=1536, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=1536, out_features=384, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (3): FocalNetLayer(
                    (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=384, out_features=771, bias=True)
                      (projection_context): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=384, out_features=384, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): FocalNetDropPath(p=0.06363636255264282)
                    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=384, out_features=1536, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=1536, out_features=384, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (4): FocalNetLayer(
                    (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=384, out_features=771, bias=True)
                      (projection_context): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=384, out_features=384, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): FocalNetDropPath(p=0.0727272778749466)
                    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=384, out_features=1536, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=1536, out_features=384, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (5): FocalNetLayer(
                    (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=384, out_features=771, bias=True)
                      (projection_context): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=384, out_features=384, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): FocalNetDropPath(p=0.08181818574666977)
                    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=384, out_features=1536, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=1536, out_features=384, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                )
                (downsample): FocalNetPatchEmbeddings(
                  (projection): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
                  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                )
              )
              (3): FocalNetStage(
                (layers): ModuleList(
                  (0): FocalNetLayer(
                    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=768, out_features=1539, bias=True)
                      (projection_context): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=768, out_features=768, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): FocalNetDropPath(p=0.09090909361839294)
                    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=768, out_features=3072, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=3072, out_features=768, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                  (1): FocalNetLayer(
                    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                    (modulation): FocalNetModulation(
                      (projection_in): Linear(in_features=768, out_features=1539, bias=True)
                      (projection_context): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
                      (activation): GELU(approximate='none')
                      (projection_out): Linear(in_features=768, out_features=768, bias=True)
                      (projection_dropout): Dropout(p=0.0, inplace=False)
                      (focal_layers): ModuleList(
                        (0): Sequential(
                          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
                          (1): GELU(approximate='none')
                        )
                        (1): Sequential(
                          (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)
                          (1): GELU(approximate='none')
                        )
                      )
                    )
                    (drop_path): FocalNetDropPath(p=0.10000000149011612)
                    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                    (mlp): FocalNetMlp(
                      (fc1): Linear(in_features=768, out_features=3072, bias=True)
                      (activation): GELUActivation()
                      (fc2): Linear(in_features=3072, out_features=768, bias=True)
                      (drop): Dropout(p=0.0, inplace=False)
                    )
                  )
                )
              )
            )
          )
          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (pooler): AdaptiveAvgPool1d(output_size=1)
        )
        (hidden_states_norms): ModuleList(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder): MaskFormerPixelDecoder(
        (fpn): MaskFormerFPNModel(
          (stem): MaskFormerFPNConvLayer(
            (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): GroupNorm(32, 256, eps=1e-05, affine=True)
            (2): ReLU(inplace=True)
          )
          (layers): Sequential(
            (0): MaskFormerFPNLayer(
              (proj): Sequential(
                (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              )
              (block): MaskFormerFPNConvLayer(
                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
                (2): ReLU(inplace=True)
              )
            )
            (1): MaskFormerFPNLayer(
              (proj): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              )
              (block): MaskFormerFPNConvLayer(
                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
                (2): ReLU(inplace=True)
              )
            )
            (2): MaskFormerFPNLayer(
              (proj): Sequential(
                (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
              )
              (block): MaskFormerFPNConvLayer(
                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (1): GroupNorm(32, 256, eps=1e-05, affine=True)
                (2): ReLU(inplace=True)
              )
            )
          )
        )
        (mask_projection): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (transformer_module): MaskFormerTransformerModule(
      (position_embedder): MaskFormerSinePositionEmbedding()
      (queries_embedder): Embedding(100, 256)
      (input_projection): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      (decoder): DetrDecoder(
        (layers): ModuleList(
          (0-5): 6 x DetrDecoderLayer(
            (self_attn): DetrAttention(
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (activation_fn): ReLU()
            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (encoder_attn): DetrAttention(
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=256, out_features=2048, bias=True)
            (fc2): Linear(in_features=2048, out_features=256, bias=True)
            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (class_predictor): Linear(in_features=256, out_features=151, bias=True)
  (mask_embedder): MaskformerMLPPredictionHead(
    (0): PredictionBlock(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ReLU()
    )
    (1): PredictionBlock(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ReLU()
    )
    (2): PredictionBlock(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): Identity()
    )
  )
  (matcher): Matcher MaskFormerHungarianMatcher
      cost_class: 1.0
      cost_mask: 20.0
      cost_dice: 1.0
  (criterion): MaskFormerLoss(
    (matcher): Matcher MaskFormerHungarianMatcher
        cost_class: 1.0
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
